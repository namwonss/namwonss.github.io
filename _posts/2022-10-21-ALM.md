---
layout: single
title: "Augmented Lagrangian amd Method of Multipliers (ALM)"
categories:
 - Algorithm
use_math: true
---
The dual ascent requires conditions to ensure convergence. The limitation of dual ascent is solved by augmented Lagrangian method, also called method of multipliers.

<br/>

This method is to robust dual ascent.
- Convergence without assumptions like strict convexity or finiteness of $f$.

<br/>

Consider the augmented Lagrangian function,

<br/>

<center>$L(x, y) = f(x) + y^{T}(Ax-b)+\frac{\rho}{2}\left \| Ax-b \right \|^{2}_{2}$</center>

<br/>

where $\rho > 0$ is the penalty parameter.

<br/>

The augmented Lagrangian can be regarded as the un augmented lagrangian associated with the constraints,

<br/>

<center>$\min_{x\in\mathbb{R}^{n}} f(x)+ \frac{\rho}{2} \left \| Ax-b \right \|^{2}_{2}$</center>

<br/>

<center>$s.t. \ Ax=b$</center>

<br/>

Clearly equivalent to original problem. Hence the both equation are same, because for any feasible $x$, the term $\frac{\rho}{2} \left \|\| Ax-b \right \|\|^{2}_{2}$ becomes zero.

<br/>

The associated dual function is as follows,

<br/>

<center>$g_{\rho}(y) = l_{\rho}(x,y)$</center>

<br/>

Then, adding term $\frac{\rho}{2} \left \|\| Ax-b \right \|\|^{2}_{2}$


to $f\left ( x \right )$ makes $g_{\rho}(y)$ differentiable under rather mild conditions than on the original problem.

<br/>

Applying dual ascent to the modified algorithm is as follows,

<br/>

<center>$x^{k+1}=argmin_{x\in \mathbb{R}^n}\ L\left (x, y^{k}\right )$</center>

<br/>

<center>$y^{k+1}=y^{k}+\rho\left ( Ax^{k+1}-b \right )$.</center>

<br/>

Now here's a question. Why is the convergence of ALM better than duan ascent?

<br/>

Since $x^{k}$ minimizes

<br/>

<center>$f \left ( x \right ) + \left ( u^{k-1} \right )^{T}Ax+\frac{\rho}{2} \left \| Ax-b \right \|^{2}_{2}$</center>

<br/>

over $x$, we have,

<br/>

<center>$0 \in \partial  f\left ( x^{k} \right )+A^{T}\left ( u^{k-1}+\rho\left ( Ax^{k}-b \right ) \right )$</center>

<br/>

<center>$= \partial  f\left ( x^{k} \right )+A^{T}u^{k}$</center>

<br/>

This is the stationarity condition for original primal problem under mild condition

<br/>

<center>$Ax^{k}-b\rightarrow 0$</center>

<br/>

as

<br/>

<center>$k \rightarrow \infty$</center>

<br/>

, so Karush–Kuhn–Tucker (KKT) conditions are satisfied in the limit and $x^{k}$, $u^{k}$ converge to solutions.

<br/>

The advantage of ALM is that much better convergence properties. However, the disadvantage of ALM is the loss of decomposability.

<br/>

**There's always a trade-off**

<br/>


